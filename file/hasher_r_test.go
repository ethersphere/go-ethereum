package file

import (
	"bytes"
	"fmt"
	"strconv"
	"strings"
	"testing"

	"github.com/ethereum/go-ethereum/common/hexutil"
	"github.com/ethersphere/swarm/bmt"
	"github.com/ethersphere/swarm/log"
	"github.com/ethersphere/swarm/testutil"
	"golang.org/x/crypto/sha3"
)

// TestReferenceFileHasherDanglingChunk explicitly tests the edge case where a single chunk hash after a balanced tree
// should skip to the level with a single reference
func TestReferenceFileHasherDanglingChunk(t *testing.T) {
	t.Skip("too big")
	pool := bmt.NewTreePool(sha3.NewLegacyKeccak256, branches, bmt.PoolSize)
	h := bmt.New(pool)
	r, data := testutil.SerialData(chunkSize*branches*branches+sectionSize, 255, 0)
	fh := NewReferenceFileHasher(h, branches)
	leftHash := fh.Hash(r, chunkSize*branches*branches)

	h = bmt.New(pool)
	fh = NewReferenceFileHasher(h, branches)
	rightHash := fh.Hash(bytes.NewBuffer(data[chunkSize*branches*branches:]), sectionSize)
	log.Info("left", "h", hexutil.Encode(leftHash))
	log.Info("right", "h", hexutil.Encode(rightHash))

	h = bmt.New(pool)
	span := lengthToSpan(chunkSize * branches * branches * sectionSize)
	h.ResetWithLength(span)
	h.Write(leftHash)
	h.Write(rightHash)
	topHash := h.Sum(nil)
	log.Info("top", "h", hexutil.Encode(topHash))
}

// TestReferenceFileHasher executes the file hasher algorithms on serial input data of periods of 0-254
// of lengths defined in common_test.go
//
// the "expected" array in common_test.go is generated by this implementation, and test failure due to
// result mismatch is nothing else than an indication that something has changed in the reference filehasher
// or the underlying hashing algorithm
func TestReferenceFileHasher(t *testing.T) {
	pool := bmt.NewTreePool(sha3.NewLegacyKeccak256, branches, bmt.PoolSize)
	h := bmt.New(pool)
	var mismatch int
	for i := start; i < end; i++ {
		dataLength := dataLengths[i]
		log.Info("start", "i", i, "len", dataLength)
		fh := NewReferenceFileHasher(h, branches)
		r, data := testutil.SerialData(dataLength, 255, 0)
		refHash := fh.Hash(r, len(data))
		eq := true
		if expected[i] != fmt.Sprintf("%x", refHash) {
			mismatch++
			eq = false
		}
		t.Logf("[%7d+%4d]\t%v\tref: %x\texpect: %s", dataLength/chunkSize, dataLength%chunkSize, eq, refHash, expected[i])
	}
	if mismatch > 0 {
		t.Fatalf("mismatches: %d/%d", mismatch, end-start)
	}
}

// BenchmarkReferenceHasher establishes a baseline for a fully synchronous file hashing operation
// it will be vastly inefficient
func BenchmarkReferenceHasher(b *testing.B) {
	for i := start; i < end; i++ {
		b.Run(fmt.Sprintf("%d", dataLengths[i]), benchmarkReferenceFileHasher)
	}
}

func benchmarkReferenceFileHasher(b *testing.B) {
	params := strings.Split(b.Name(), "/")
	dataLength, err := strconv.ParseInt(params[1], 10, 64)
	if err != nil {
		b.Fatal(err)
	}
	r, data := testutil.SerialData(int(dataLength), 255, 0)
	pool := bmt.NewTreePool(sha3.NewLegacyKeccak256, branches, bmt.PoolSize)
	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		h := bmt.New(pool)
		fh := NewReferenceFileHasher(h, branches)
		fh.Hash(r, len(data))
	}
}
